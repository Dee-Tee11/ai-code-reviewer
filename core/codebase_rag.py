"""
Sistema RAG para AI Code Reviewer
Indexa codebase e fornece contexto relevante para reviews
"""

import os
import json
import hashlib
from pathlib import Path
from typing import List, Dict, Optional, Set, Tuple
from dataclasses import dataclass, asdict
import chromadb
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üìä DATA CLASSES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@dataclass
class CodeChunk:
    """Representa um peda√ßo de c√≥digo indexado"""
    id: str
    type: str  # "file", "function", "class", "component"
    path: str
    name: str
    content: str
    language: str
    line_start: int
    line_end: int
    imports: List[str]
    exports: List[str]
    parent_file: Optional[str]
    last_modified: str
    commit_sha: Optional[str]

@dataclass
class RetrievalContext:
    """Contexto recuperado do RAG"""
    similar_files: List[Dict]  # Ficheiros semanticamente similares
    related_functions: List[Dict]  # Fun√ß√µes/componentes relacionados
    dependencies: Dict[str, List[str]]  # Grafo de depend√™ncias
    architecture_docs: List[Dict]  # Documenta√ß√£o relevante


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üß† CODEBASE RAG
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class CodebaseRAG:
    """Sistema RAG para indexa√ß√£o e retrieval de c√≥digo"""
    
    def __init__(self, 
                 persist_directory: str = "./chroma_db",
                 model_name: str = "all-MiniLM-L6-v2"):
        """
        Inicializa o sistema RAG
        
        Args:
            persist_directory: Diret√≥rio para persistir ChromaDB
            model_name: Nome do modelo de embeddings
        """
        self.persist_dir = Path(persist_directory)
        self.persist_dir.mkdir(exist_ok=True)
        
        # Inicializar modelo de embeddings
        print(f"üß† Loading embedding model: {model_name}")
        self.embedding_model = SentenceTransformer(model_name)
        
        # Inicializar ChromaDB
        print(f"üíæ Initializing ChromaDB at {persist_directory}")
        self.client = chromadb.PersistentClient(
            path=str(self.persist_dir),
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )
        
        # Criar/obter cole√ß√µes
        self.files_collection = self.client.get_or_create_collection(
            name="files",
            metadata={"hnsw:space": "cosine"}
        )
        
        self.functions_collection = self.client.get_or_create_collection(
            name="functions",
            metadata={"hnsw:space": "cosine"}
        )
        
        # Grafo de depend√™ncias (armazenado localmente)
        self.dependency_graph_path = self.persist_dir / "dependencies.json"
        self.dependency_graph = self._load_dependency_graph()
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üì• INDEXA√á√ÉO
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def index_file(self, chunk: CodeChunk) -> bool:
        """
        Indexa um ficheiro completo (N√≠vel 1)
        
        Args:
            chunk: CodeChunk com informa√ß√£o do ficheiro
            
        Returns:
            True se indexado com sucesso
        """
        try:
            # Gerar embedding
            embedding = self.embedding_model.encode(chunk.content).tolist()
            
            # Adicionar √† cole√ß√£o de ficheiros
            self.files_collection.add(
                ids=[chunk.id],
                embeddings=[embedding],
                documents=[chunk.content],
                metadatas=[{
                    "type": chunk.type,
                    "path": chunk.path,
                    "name": chunk.name,
                    "language": chunk.language,
                    "line_start": chunk.line_start,
                    "line_end": chunk.line_end,
                    "imports": json.dumps(chunk.imports),
                    "exports": json.dumps(chunk.exports),
                    "last_modified": chunk.last_modified,
                    "commit_sha": chunk.commit_sha or ""
                }]
            )
            
            print(f"  ‚úÖ Indexed file: {chunk.path}")
            return True
            
        except Exception as e:
            print(f"  ‚ùå Error indexing {chunk.path}: {e}")
            return False
    
    def index_function(self, chunk: CodeChunk) -> bool:
        """
        Indexa uma fun√ß√£o/componente (N√≠vel 2)
        
        Args:
            chunk: CodeChunk com informa√ß√£o da fun√ß√£o
            
        Returns:
            True se indexado com sucesso
        """
        try:
            # Gerar embedding
            embedding = self.embedding_model.encode(chunk.content).tolist()
            
            # Adicionar √† cole√ß√£o de fun√ß√µes
            self.functions_collection.add(
                ids=[chunk.id],
                embeddings=[embedding],
                documents=[chunk.content],
                metadatas=[{
                    "type": chunk.type,
                    "path": chunk.path,
                    "name": chunk.name,
                    "language": chunk.language,
                    "line_start": chunk.line_start,
                    "line_end": chunk.line_end,
                    "parent_file": chunk.parent_file or "",
                    "last_modified": chunk.last_modified,
                    "commit_sha": chunk.commit_sha or ""
                }]
            )
            
            return True
            
        except Exception as e:
            print(f"  ‚ùå Error indexing function {chunk.name}: {e}")
            return False
    
    def update_dependencies(self, filepath: str, imports: List[str], exports: List[str]):
        """
        Atualiza o grafo de depend√™ncias (N√≠vel 3)
        
        Args:
            filepath: Caminho do ficheiro
            imports: Lista de imports
            exports: Lista de exports
        """
        # Adicionar/atualizar n√≥ no grafo
        self.dependency_graph[filepath] = {
            "imports": imports,
            "exports": exports,
            "imported_by": []
        }
        
        # Atualizar imported_by nos ficheiros que este importa
        for imported_file in imports:
            if imported_file in self.dependency_graph:
                if filepath not in self.dependency_graph[imported_file]["imported_by"]:
                    self.dependency_graph[imported_file]["imported_by"].append(filepath)
        
        # Salvar grafo
        self._save_dependency_graph()
    
    def delete_file_chunks(self, filepath: str):
        """
        Remove todos os chunks de um ficheiro
        (√∫til para re-indexa√ß√£o)
        
        Args:
            filepath: Caminho do ficheiro a remover
        """
        file_id = f"file:{filepath}"
        
        try:
            # Remover ficheiro
            self.files_collection.delete(ids=[file_id])
            
            # Remover fun√ß√µes desse ficheiro
            results = self.functions_collection.get(
                where={"parent_file": file_id}
            )
            
            if results['ids']:
                self.functions_collection.delete(ids=results['ids'])
            
            # Remover do grafo de depend√™ncias
            if filepath in self.dependency_graph:
                del self.dependency_graph[filepath]
                self._save_dependency_graph()
            
            print(f"  üóëÔ∏è Deleted chunks for: {filepath}")
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error deleting {filepath}: {e}")
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üîç RETRIEVAL
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def get_context(self, 
                    filepath: str, 
                    patch: Optional[str] = None,
                    top_k: int = 5) -> RetrievalContext:
        """
        Obt√©m contexto relevante para um ficheiro modificado
        
        Args:
            filepath: Caminho do ficheiro modificado
            patch: Diff do commit (opcional)
            top_k: N√∫mero de resultados a retornar por categoria
            
        Returns:
            RetrievalContext com contexto relevante
        """
        print(f"üîç Retrieving context for: {filepath}")
        
        # 1. Buscar ficheiros similares (N√≠vel 1)
        similar_files = self._search_similar_files(filepath, patch, top_k)
        
        # 2. Buscar fun√ß√µes relacionadas (N√≠vel 2)
        related_functions = self._search_related_functions(filepath, patch, top_k)
        
        # 3. Buscar depend√™ncias (N√≠vel 3)
        dependencies = self._get_dependencies(filepath)
        
        # 4. Buscar documenta√ß√£o relevante
        architecture_docs = self._search_architecture_docs(filepath, top_k=2)
        
        context = RetrievalContext(
            similar_files=similar_files,
            related_functions=related_functions,
            dependencies=dependencies,
            architecture_docs=architecture_docs
        )
        
        return context
    
    def _search_similar_files(self, 
                              filepath: str, 
                              patch: Optional[str],
                              top_k: int) -> List[Dict]:
        """Busca ficheiros semanticamente similares"""
        try:
            # Usar patch se dispon√≠vel, sen√£o buscar ficheiro atual
            query_text = patch if patch else self._get_file_content(filepath)
            
            if not query_text:
                return []
            
            # Gerar embedding da query
            query_embedding = self.embedding_model.encode(query_text).tolist()
            
            # Buscar similares
            results = self.files_collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k + 1  # +1 porque pode incluir o pr√≥prio ficheiro
            )
            
            # Filtrar o pr√≥prio ficheiro e formatar resultados
            similar = []
            for i, doc_id in enumerate(results['ids'][0]):
                if doc_id != f"file:{filepath}":
                    similar.append({
                        "id": doc_id,
                        "path": results['metadatas'][0][i]['path'],
                        "content": results['documents'][0][i],
                        "distance": results['distances'][0][i] if 'distances' in results else None
                    })
            
            return similar[:top_k]
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error searching similar files: {e}")
            return []
    
    def _search_related_functions(self,
                                  filepath: str,
                                  patch: Optional[str],
                                  top_k: int) -> List[Dict]:
        """Busca fun√ß√µes/componentes relacionados"""
        try:
            query_text = patch if patch else self._get_file_content(filepath)
            
            if not query_text:
                return []
            
            # Gerar embedding
            query_embedding = self.embedding_model.encode(query_text).tolist()
            
            # Buscar fun√ß√µes similares
            results = self.functions_collection.query(
                query_embeddings=[query_embedding],
                n_results=top_k
            )
            
            # Formatar resultados
            functions = []
            for i, doc_id in enumerate(results['ids'][0]):
                functions.append({
                    "id": doc_id,
                    "name": results['metadatas'][0][i]['name'],
                    "path": results['metadatas'][0][i]['path'],
                    "content": results['documents'][0][i],
                    "distance": results['distances'][0][i] if 'distances' in results else None
                })
            
            return functions
            
        except Exception as e:
            print(f"  ‚ö†Ô∏è Error searching related functions: {e}")
            return []
    
    def _get_dependencies(self, filepath: str) -> Dict[str, List[str]]:
        """Obt√©m depend√™ncias diretas do ficheiro"""
        if filepath not in self.dependency_graph:
            return {"imports": [], "imported_by": []}
        
        node = self.dependency_graph[filepath]
        return {
            "imports": node.get("imports", []),
            "imported_by": node.get("imported_by", [])
        }
    
    def _search_architecture_docs(self, filepath: str, top_k: int) -> List[Dict]:
        """Busca documenta√ß√£o de arquitetura relevante"""
        # TODO: Implementar busca em READMEs, docs, etc.
        # Por agora retorna vazio
        return []
    
    def _get_file_content(self, filepath: str) -> Optional[str]:
        """Obt√©m conte√∫do de um ficheiro do √≠ndice"""
        try:
            file_id = f"file:{filepath}"
            result = self.files_collection.get(ids=[file_id])
            
            if result['documents']:
                return result['documents'][0]
            return None
            
        except:
            return None
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üíæ PERSISTENCE
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def _load_dependency_graph(self) -> Dict:
        """Carrega grafo de depend√™ncias do disco"""
        if self.dependency_graph_path.exists():
            try:
                with open(self.dependency_graph_path) as f:
                    return json.load(f)
            except:
                return {}
        return {}
    
    def _save_dependency_graph(self):
        """Salva grafo de depend√™ncias no disco"""
        try:
            with open(self.dependency_graph_path, 'w') as f:
                json.dump(self.dependency_graph, f, indent=2)
        except Exception as e:
            print(f"‚ö†Ô∏è Error saving dependency graph: {e}")
    
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # üìä STATS & UTILITIES
    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    def get_stats(self) -> Dict:
        """Retorna estat√≠sticas do √≠ndice"""
        files_count = self.files_collection.count()
        functions_count = self.functions_collection.count()
        dependencies_count = len(self.dependency_graph)
        
        return {
            "total_files": files_count,
            "total_functions": functions_count,
            "total_dependencies": dependencies_count,
            "storage_path": str(self.persist_dir)
        }
    
    def reset(self):
        """Reset completo do √≠ndice (cuidado!)"""
        self.client.reset()
        self.dependency_graph = {}
        self._save_dependency_graph()
        print("üóëÔ∏è Index reset complete")


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üîß HELPER: Gerar ID √∫nico
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def generate_chunk_id(type: str, path: str, name: str, line_start: int) -> str:
    """
    Gera ID √∫nico para um chunk
    
    Args:
        type: "file" ou "function"
        path: Caminho do ficheiro
        name: Nome da fun√ß√£o/componente
        line_start: Linha inicial
        
    Returns:
        ID √∫nico no formato: "type:path:name:line"
    """
    if type == "file":
        return f"file:{path}"
    else:
        return f"func:{path}:{name}:{line_start}"